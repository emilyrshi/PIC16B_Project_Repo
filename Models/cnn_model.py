# -*- coding: utf-8 -*-
"""CNN_Model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nGC2xET1V9dC1SEg_FPxYbuCN9prm6F6
"""

import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import datasets, layers, models
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
from keras.models import load_model
from keras.preprocessing import image
import matplotlib.pyplot as plt
from google.colab import drive
import os
import cv2

"""# Importing Dataset"""

# Importing CSV from GitHub
sign_language_url = "https://raw.githubusercontent.com/emilyrshi/PIC16B_Project_Repo/6e27757ed9a716812ef7acfc855be8521285a464/SignLanguage_CSV/sign_language_dataset.csv"

sign_language_data = pd.read_csv(sign_language_url, index_col = False)
sign_language_data.head()

"""# Data Cleaning and Preparation"""

# Separate image features and target labels
X = sign_language_data.iloc[:, 1:785]
y = sign_language_data['Letter']

# Converting data to numpy arrays
X = X.to_numpy()
y = y.to_numpy()

# Reshape input features into 4 dimensional tensor
X = X.reshape(-1, 28, 28, 1)

# Convert target labels to one-hot encoding
y = pd.get_dummies(y)
y = y.to_numpy()

# Split the dataset into training and validation sets
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state = 42) # random_State = 42

"""# CNN Model One"""

cnn_one_model = models.Sequential([
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(128, (3, 3), activation='relu'),
    layers.Flatten(),
    layers.Dense(128, activation='relu'),
    layers.Dense(7, activation='softmax')  # number of classes (7 letters)
])

# Compiling the model
cnn_one_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

cnn_one_history = cnn_one_model.fit(X_train, y_train, epochs=20, validation_data=(X_val, y_val))

plt.plot(cnn_one_history.history["accuracy"], label = "training")
plt.plot(cnn_one_history.history["val_accuracy"], label = "validation")
plt.gca().set(xlabel = "epoch", ylabel = "accuracy")
plt.legend()

"""# CNN Model Two"""

cnn_two_model = models.Sequential([
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(128, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Flatten(),
    layers.Dense(256, activation='relu'),
    layers.Dropout(0.5),
    layers.Dense(128, activation='relu'),
    layers.Dense(7, activation='softmax')
])

# Compiling the model
cnn_two_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

cnn_two_history = cnn_two_model.fit(X_train, y_train, epochs=20, validation_data=(X_val, y_val))

plt.plot(cnn_two_history.history["accuracy"], label = "training")
plt.plot(cnn_two_history.history["val_accuracy"], label = "validation")
plt.gca().set(xlabel = "epoch", ylabel = "accuracy")
plt.legend()

"""# CNN Model Three"""

cnn_three_model = models.Sequential([
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Flatten(),
    layers.Dropout(0.5),
    layers.Dense(128, activation='relu'),
    layers.Dense(7, activation='softmax')
])

# Compiling the model
cnn_three_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

cnn_three_history = cnn_three_model.fit(X_train, y_train, epochs=20, validation_data=(X_val, y_val))

plt.plot(cnn_three_history.history["accuracy"], label = "training")
plt.plot(cnn_three_history.history["val_accuracy"], label = "validation")
plt.gca().set(xlabel = "epoch", ylabel = "accuracy")
plt.legend()

"""# **Evaluating Model on Testing Data**"""

# Evaluate accuracy on testing
loss, accuracy = cnn_three_model.evaluate(X_val, y_val)

"""## **Classification on Unseen Image**"""

import prediction
from prediction import load_image, predict_images

# Define labels
labels = {
    0: 'D',
    1: 'E',
    2: 'H',
    3: 'L',
    4: 'O',
    5: 'R',
    6: 'W'
}

# Specify directory containing images to predict
folder_dir = 'Models/PredictionImages'

# Assuming cnn_three_model is defined elsewhere
model = cnn_three_model

# Perform prediction
predict_images(folder_dir, model, labels)