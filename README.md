# PIC16B - American Sign Language Gesture Recognition 
(Emily Shi, Yuka Murakami, Shaina Wang)

Hello! Welcome to the American Sign Language Gesture Recognition demonstration. We will be demonstrating various models that classifies images of ASL hand gestures. First up is the tensorflow keras sequential model. Then, the pre-existing resnet18 CNN model will be used for test data to predict outcomes. 

In order to see the images being divided, trained, and tested through the models, copy our notebooks to a Google Colab and run it. You can access our TensorFlow Keras Sequential Model on Github at Models/TF_Keras_CNN_Model. You can access the Resnet18 pretrained model by going to ResNet_Pretrained_Model/ResNet18(Custom_Dataset)_Emily.ipynb. Make sure to include the folders SignLanguageImages and SignLanguage_CSV in your directory so that the images can be accessed. 
